{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 64 \n",
      "\n",
      "Number of parameters: 79,782,552\n",
      "Epoch: 250. Loss: 4.000. Loss: 3.906\n",
      "Epoch: 500. Loss: 3.399. Loss: 3.337\n",
      "Epoch: 750. Loss: 3.063. Loss: 3.148\n",
      "Epoch: 1000. Loss: 3.017. Loss: 2.904\n",
      "Epoch: 1250. Loss: 2.871. Loss: 2.863\n",
      "Epoch: 1500. Loss: 2.753. Loss: 2.881\n",
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 64 \n",
      "\n",
      "Number of parameters: 79,782,552\n",
      "Epoch: 250. Loss: 3.720. Loss: 3.573\n",
      "Epoch: 500. Loss: 3.107. Loss: 3.031\n",
      "Epoch: 750. Loss: 3.000. Loss: 3.013\n",
      "Epoch: 1000. Loss: 2.885. Loss: 2.864\n",
      "Epoch: 1250. Loss: 2.812. Loss: 2.778\n",
      "Epoch: 1500. Loss: 2.700. Loss: 2.750\n",
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 64 \n",
      "\n",
      "Number of parameters: 79,782,552\n",
      "Epoch: 250. Loss: 3.608. Loss: 3.643\n",
      "Epoch: 500. Loss: 3.196. Loss: 3.084\n",
      "Epoch: 750. Loss: 2.915. Loss: 2.959\n",
      "Epoch: 1000. Loss: 2.800. Loss: 2.841\n",
      "Epoch: 1250. Loss: 2.792. Loss: 2.883\n",
      "Epoch: 1500. Loss: 2.758. Loss: 2.794\n",
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 64 \n",
      "\n",
      "Number of parameters: 79,782,552\n",
      "Epoch: 250. Loss: 3.998. Loss: 3.922\n",
      "Epoch: 500. Loss: 3.347. Loss: 3.377\n",
      "Epoch: 750. Loss: 3.153. Loss: 3.166\n",
      "Epoch: 1000. Loss: 2.990. Loss: 3.000\n",
      "Epoch: 1250. Loss: 2.971. Loss: 2.918\n",
      "Epoch: 1500. Loss: 2.769. Loss: 2.833\n",
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 64 \n",
      "\n",
      "Number of parameters: 79,782,552\n",
      "Epoch: 250. Loss: 3.685. Loss: 3.646\n",
      "Epoch: 500. Loss: 3.211. Loss: 3.079\n",
      "Epoch: 750. Loss: 2.990. Loss: 3.036\n",
      "Epoch: 1000. Loss: 2.866. Loss: 2.827\n",
      "Epoch: 1250. Loss: 2.779. Loss: 2.754\n",
      "Epoch: 1500. Loss: 2.704. Loss: 2.677\n",
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 64 \n",
      "\n",
      "Number of parameters: 79,782,552\n",
      "Epoch: 250. Loss: 3.520. Loss: 3.610\n",
      "Epoch: 500. Loss: 3.109. Loss: 3.140\n",
      "Epoch: 750. Loss: 2.950. Loss: 2.971\n",
      "Epoch: 1000. Loss: 2.871. Loss: 2.893\n",
      "Epoch: 1250. Loss: 2.757. Loss: 2.854\n",
      "Epoch: 1500. Loss: 2.753. Loss: 2.733\n",
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 128 \n",
      "\n",
      "Number of parameters: 79,831,704\n",
      "Epoch: 250. Loss: 3.922. Loss: 3.919\n",
      "Epoch: 500. Loss: 3.281. Loss: 3.278\n",
      "Epoch: 750. Loss: 3.136. Loss: 3.008\n",
      "Epoch: 1000. Loss: 2.862. Loss: 2.922\n",
      "Epoch: 1250. Loss: 2.799. Loss: 2.790\n",
      "Epoch: 1500. Loss: 2.724. Loss: 2.628\n",
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 128 \n",
      "\n",
      "Number of parameters: 79,831,704\n",
      "Epoch: 250. Loss: 3.543. Loss: 3.519\n",
      "Epoch: 500. Loss: 2.981. Loss: 2.985\n",
      "Epoch: 750. Loss: 2.808. Loss: 2.890\n",
      "Epoch: 1000. Loss: 2.713. Loss: 2.682\n",
      "Epoch: 1250. Loss: 2.616. Loss: 2.613\n",
      "Epoch: 1500. Loss: 2.500. Loss: 2.444\n",
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 128 \n",
      "\n",
      "Number of parameters: 79,831,704\n",
      "Epoch: 250. Loss: 3.506. Loss: 3.503\n",
      "Epoch: 500. Loss: 2.948. Loss: 2.938\n",
      "Epoch: 750. Loss: 2.808. Loss: 2.826\n",
      "Epoch: 1000. Loss: 2.674. Loss: 2.606\n",
      "Epoch: 1250. Loss: 2.614. Loss: 2.562\n",
      "Epoch: 1500. Loss: 2.467. Loss: 2.503\n",
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 2 \n",
      "block_size: 128 \n",
      "\n",
      "Number of parameters: 79,831,704\n",
      "Epoch: 250. Loss: 3.950. Loss: 3.989\n",
      "Epoch: 500. Loss: 3.292. Loss: 3.327\n",
      "Epoch: 750. Loss: 3.122. Loss: 3.087\n",
      "Epoch: 1000. Loss: 2.832. Loss: 2.888\n",
      "Epoch: 1250. Loss: 2.784. Loss: 2.797\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')  \n",
    "\n",
    "from Classes.tokenizer import Tokenizer as T\n",
    "from utils import Trainer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Possible hyperparameters to search over\n",
    "block_size_values = [64,128,256]\n",
    "dropout_values = [0.2,0.3]\n",
    "lr_values = [1e-4, 3e-4, 5e-4]\n",
    "run_count = 0\n",
    "\n",
    "# block_size = 128\n",
    "batch_size = 32\n",
    "n_heads = 2\n",
    "n_layers = 8\n",
    "d_model = 768\n",
    "# dropout = 0.2\n",
    "# learning_rate = 3e-4\n",
    "epochs = 1_500\n",
    "eval_iters = 10\n",
    "vocab_size = 15_000\n",
    "\n",
    "# Define static attributes\n",
    "static_attributes = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'n_heads': n_heads,\n",
    "    'n_layers': n_layers,\n",
    "    'device': device,\n",
    "    'd_model': d_model,\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "    'eval_iters': eval_iters\n",
    "}\n",
    "\n",
    "train = torch.load('train.pt')\n",
    "val = torch.load('val.pt')\n",
    "\n",
    "for block_size in block_size_values:\n",
    "    for dropout in dropout_values:\n",
    "        for learning_rate in lr_values:\n",
    "            dff = d_model * 4  # Assuming dff is always 4 * d_model\n",
    "            \n",
    "            variable_attributes = {\n",
    "                'dropout': dropout,\n",
    "                'block_size': block_size,\n",
    "                'learning_rate': learning_rate,\n",
    "                'dff': dff\n",
    "            }\n",
    "            \n",
    "            all_attributes = {**static_attributes, **variable_attributes}\n",
    "            trainer = Trainer(**all_attributes)\n",
    "            trainer.load_data(train=train, val=val)\n",
    "            trainer.train_model()\n",
    "            run_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
