{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters \n",
      "n_layers: 8 \n",
      "d_model: 768 \n",
      "n_heads: 4 \n",
      "block_size: 128 \n",
      "\n",
      "Number of parameters: 60,945,048\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sentencepiece as spm\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')  \n",
    "\n",
    "from Classes.myGPT import Model  \n",
    "from Classes.tokenizer import Tokenizer as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = f'data/tokenized inputs/'\n",
    "\n",
    "block_size = 128\n",
    "batch_size = 64\n",
    "n_heads = 4\n",
    "n_layers = 8\n",
    "d_model = 192 * n_heads\n",
    "dff = d_model * 2\n",
    "dropout = 0.2\n",
    "learning_rate = 3e-4\n",
    "# epochs = 7500\n",
    "eval_iters = 20\n",
    "vocab_size = 15_000\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(m, train_dl, val_dl, eval_iters):\n",
    "\n",
    "    m.eval()\n",
    "    out = {}\n",
    "    \n",
    "    for split, dl in [('train', train_dl), ('val', val_dl)]:\n",
    "        losses = []\n",
    "        for i, (X, Y) in enumerate(dl):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            logits, loss = m(X, Y)\n",
    "            losses.append(loss.item())\n",
    "            if i >= eval_iters:\n",
    "                break\n",
    "        out[split] = sum(losses) / len(losses)\n",
    "        \n",
    "    m.train()\n",
    "    return out \n",
    "\n",
    "def make_feats_labels(block_size, data):\n",
    "\n",
    "    n_sequences = data.shape[-1] // block_size\n",
    "    x = torch.stack([data[seq_num : seq_num + block_size] for seq_num in range(n_sequences)])\n",
    "    y = torch.stack([data[seq_num + 1 : seq_num + block_size + 1] for seq_num in range(n_sequences)])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "class TinyStoryDS(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.x, self.y = make_feats_labels(block_size, dataset)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x) \n",
    "\n",
    "# with open('data/tinystoriesv2-gpt4-valid.txt', 'r') as val_file:\n",
    "#     val_text = val_file.read()\n",
    "\n",
    "t = T()\n",
    "# val = torch.tensor(t.encode(val_text, False, False), dtype=torch.long)\n",
    "# torch.save(val, 'val.pt')\n",
    "\n",
    "val = torch.load('val.pt')\n",
    "val_set = TinyStoryDS(val)\n",
    "val_dl = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "m = Model(  vocab_size=vocab_size, \n",
    "            block_size=block_size,\n",
    "            dropout=dropout,\n",
    "            dff=dff,\n",
    "            n_layers=n_layers,\n",
    "            n_heads=n_heads,\n",
    "            d_model=d_model).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "n_params = sum(p.nelement() for p in m.parameters())\n",
    "print(f'Number of parameters: {n_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing tns_chunk_0.pt\n",
      "100%|██████████| 1304/1304 [16:56<00:00,  1.28it/s]\n",
      "INFO:root:Processing tns_chunk_1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.670. Evaluation Loss: 4.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1304/1304 [16:54<00:00,  1.29it/s]\n",
      "INFO:root:Processing tns_chunk_10.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.226. Evaluation Loss: 3.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1085/1304 [14:05<02:50,  1.28it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m     logits, loss \u001b[39m=\u001b[39m m(Xb,Yb)\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m l \u001b[39m=\u001b[39m estimate_loss(m, train_dl, val_dl, eval_iters)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "files = os.listdir(data_path)  # List all files in the directory specified by data_path\n",
    "n_files = 0\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.pt'):\n",
    "\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        logging.info(f'Processing {file}')\n",
    "\n",
    "        train_set = TinyStoryDS(torch.load(f'{data_path}{file}'))\n",
    "        train_dl = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "        num_samples = len(train_set)\n",
    "        n_iterations = num_samples//batch_size\n",
    "\n",
    "        for i, (Xb, Yb) in enumerate(tqdm(train_dl)):\n",
    "            Xb, Yb = Xb.to(device), Yb.to(device)\n",
    "            logits, loss = m(Xb,Yb)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        l = estimate_loss(m, train_dl, val_dl, eval_iters)\n",
    "        print(f\"Training Loss: {l['train']:.3f}. Evaluation Loss: {l['val']:.3f}\")\n",
    "        n_files =+ 1\n",
    "        if n_files >= 15:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It ⁇  ⁇ It ⁇ s try and started stuck. ⁇  ⁇ Maybe ⁇  The fairy replied,  ⁇ I ⁇ If ⁇ t know what ⁇ What is not right. <|endoftext|> Once upon a time, there was a little girl named Lily. The bird liked to explore the owl was scared and pretty ⁇  a little girl. This listened. The fox was very excited. It is not know what she did. It's friend was a loud of a little of a story with her friends. You loved to read books and made her mum in the sky. One day, Lily went to find a new friend, a boy named Lily. He thought very much. When he had a dog named Max, and he decided to take some more careful, a moment. The dog had an idea. He thought the boy named Lily saw a new things. Lily was stuck in a room,\" the town, Max thought about their mom came to find Max. Lily saw Max're was very big, red. The tree liked to look too. The duck was the most on the floor. Max felt very sad. Max had been the car back to the dog. The old man said, \"I'm sorry, Spot.\" Max did not want to share it, it's okay. As they both had ever seen the dog, the dog and started to talk away the tree. The man was angry. It was so happy. She opened it back and became friends. <|endoftext|> Lily liked to run in a backyard. She liked to read books books, and her mom, and Dad are pretty. She had a lot of questions with lots of questions. She loved to help things in the room. She liked the kids. She put the dog, the dog a lot of animals like a long car. She was very excited. \"Look and Lily is okay at me at the hat. It's a loud sound. Lily felt very sad. She wanted to be good at Amy. She did not see and Amy made his friends. She thought it would be nice on a branch. She did not want to share. She gave a little bird, \"Don't, I promise in a big leaf. Do you need a few dog?\" Lily asks. She said, \"You is going on the ground. It is a big tree?\" he picked it on the ground. She said, \"Yes, my book again. She ran after the cat and they both enjoyed the cat. She said it was too strong. She opened the bird's family. The bird was very tired and thanked Max if her mommy.\" And Max felt proud. It was a red hen and helped it. He wanted the bird went outside. They did! The bird started to cry the cat. The cat was happy. They decided to the people and they played, happy. And they both shared their friends with their friends. <|endoftext|> Lily and Mia became had many words and Ben loved to whistle. One day, Lily became best dog found a big tree. It liked to do a girl named Lily. They played all day long. They took a tree. Lily liked the pretty tree. Lily wanted to pick some room and play with it. Lily had a big, red truck on his face. Lily loved her friend, Lily met a long cord named Lily. She had a friend. Lily and Ben. Lily loved to get a new friend. One day, Lily was very excited, Lily could not find it. She wanted to have fun. She saw a big rock on the branch. Lily wanted to play with. He did a yellow friend. It has a lot. It made a big, and it was going on, there. She wanted it was a little bird. \"Hey, I can help you get out. Her mother!\" Lily says. She is it too. She tries a little bird to know what is to her friend. She took the tree. She sees the bird and Lily. She took the girl made Lily. Lily was scared, her mom too, and she had a toy car. Lily had a dog named Lily. Lily was very excited. She liked to explore out to her friend, she tried to make the little bird. She did he wanted their mom to the bird and he started. She took the garden from a big pile of the town. He opened her mom was happy from. The bird were sad a secret.\" Lily was sad because he tried to try to open the little bird. She wanted a little bird tried to climb. She picked it up at Lily and gave her a tree. Lily was very excited. She looked at Lily. She wanted to go closer to look. She was so happy. She thought. She gave her a big chest. She did not get an interesting on it. She saw a tree. It was a very big on a branch of it. She wanted to help him. She thought\n"
     ]
    }
   ],
   "source": [
    "max_new_tokens = 1_000\n",
    "seed_text = t.encode('Once upon a time', True, False)\n",
    "\n",
    "seed_idx = torch.tensor(seed_text, device=device).unsqueeze(0)\n",
    "predictions = m.generate(seed_idx, max_new_tokens).to(device)\n",
    "\n",
    "first_non_zero = torch.nonzero(predictions, as_tuple=False)[0][1].item()\n",
    "predictions = predictions[:,first_non_zero:]\n",
    "\n",
    "generated_text = t.decode(predictions[0].tolist())\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_batches(block_size, batch_size, data):\n",
    "\n",
    "#     n_sequences = int(len(data) // block_size)\n",
    "\n",
    "#     x = torch.stack([data[seq_num : seq_num + block_size] for seq_num in range(n_sequences)])\n",
    "#     y = torch.stack([data[seq_num + 1 : seq_num + block_size + 1] for seq_num in range(n_sequences)])\n",
    "\n",
    "#     B,T = x.shape\n",
    "#     left_over_seqs = B % batch_size\n",
    "\n",
    "#     x = x[:B - left_over_seqs]\n",
    "#     y = y[:B - left_over_seqs]\n",
    "\n",
    "#     x = x.view(-1, batch_size, block_size)\n",
    "#     y = y.view(-1, batch_size, block_size)\n",
    "\n",
    "#     x, y = x.to(device), y.to(device)\n",
    "\n",
    "#     return x, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
