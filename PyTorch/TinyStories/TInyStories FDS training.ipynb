{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 47,153,544 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "sys.path.append('../')  \n",
    "\n",
    "from Classes.tokenizer import Tokenizer as T\n",
    "from Classes.myGPT import Model\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "data_path = f'data/tokenized_inputs/'\n",
    "runs_path = f'runs/'\n",
    "\n",
    "block_size = 128\n",
    "batch_size = 32\n",
    "n_heads = 6\n",
    "n_layers = 10\n",
    "d_model = 768\n",
    "dropout = 0.2\n",
    "learning_rate = 3e-4\n",
    "epochs = 1\n",
    "eval_iters = 25\n",
    "vocab_size = 15_000\n",
    "max_iters = 100_000\n",
    "dff = n_heads * 4\n",
    "\n",
    "static_attributes = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'n_heads': n_heads,\n",
    "    'n_layers': n_layers,\n",
    "    'device': device,\n",
    "    'd_model': d_model,\n",
    "    'batch_size': batch_size,\n",
    "    'epochs': epochs,\n",
    "    'eval_iters': eval_iters,\n",
    "    'learning_rate': learning_rate,\n",
    "    'dropout': dropout,\n",
    "    'block_size': block_size,\n",
    "    'dff': dff,\n",
    "}\n",
    "\n",
    "# FOR GENERATOR\n",
    "def make_batches(data, block_size, batch_size):\n",
    "    data_len = len(data)\n",
    "    last_ix = 0\n",
    "    \n",
    "    while last_ix + batch_size * block_size <= data_len:\n",
    "        batch_X = []\n",
    "        batch_Y = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            X = data[last_ix: last_ix + block_size]\n",
    "            Y = data[last_ix + 1: last_ix + block_size + 1]\n",
    "            batch_X.append(X)\n",
    "            batch_Y.append(Y)\n",
    "            last_ix += block_size\n",
    "        yield torch.stack(batch_X), torch.stack(batch_Y)\n",
    "\n",
    "#FOR GENERATOR\n",
    "def estimate_loss(m, train, val, block_size, batch_size, eval_iters):\n",
    "    def calculate_loss(data):\n",
    "        l = []\n",
    "        counter = 0\n",
    "        for x, y in make_batches(data, block_size, batch_size):\n",
    "            if counter >= eval_iters:\n",
    "                break\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            _, loss = m(x, y)\n",
    "            l.append(loss.item())\n",
    "            counter += 1\n",
    "        return sum(l) / len(l) if len(l) > 0 else 0.0\n",
    "    \n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calculate_loss(train)\n",
    "        val_loss = calculate_loss(val)\n",
    "    m.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def calculate_total_batches(data, block_size, batch_size):\n",
    "    return len(data) // (block_size * batch_size)\n",
    "\n",
    "# Custom learning rate scheduler\n",
    "def get_lr(it):\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * it / max_iters))\n",
    "    return learning_rate * coeff\n",
    "\n",
    "gradient_accumulation_steps = 4  # used to simulate larger batch sizes\n",
    "learning_rate = 5e-4  # max learning rate\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "warmup_iters = 1_000  # how many steps to warm up for\n",
    "\n",
    "m = Model(vocab_size=vocab_size, \n",
    "          block_size=block_size,\n",
    "          dropout=dropout,\n",
    "          dff=dff,\n",
    "          n_heads=n_heads, \n",
    "          d_model=d_model,\n",
    "          n_layers=n_layers,).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "n_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "print(f\"Model has {n_params:,} trainable parameters\")\n",
    "t = T()\n",
    "n_files = 0\n",
    "val = torch.load(f'{data_path}/val.pt')\n",
    "files = os.listdir(data_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 2.814. Val Loss: 2.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 2.328. Val Loss: 2.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 2.161. Val Loss: 2.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 2.008. Val Loss: 2.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.939. Val Loss: 2.091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:54<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.896. Val Loss: 2.043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1226/1226 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1226 | Train Loss: 1.829. Val Loss: 2.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.806. Val Loss: 1.967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.781. Val Loss: 1.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [01:25<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 226 | Train Loss: 1.575. Val Loss: 1.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.713. Val Loss: 1.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.736. Val Loss: 1.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.719. Val Loss: 1.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.702. Val Loss: 1.863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:54<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.689. Val Loss: 1.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:54<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.679. Val Loss: 1.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:54<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.641. Val Loss: 1.821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:56<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.632. Val Loss: 1.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.604. Val Loss: 1.788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.595. Val Loss: 1.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:50<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.600. Val Loss: 1.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.605. Val Loss: 1.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.552. Val Loss: 1.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.559. Val Loss: 1.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:54<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.577. Val Loss: 1.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:54<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.532. Val Loss: 1.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:53<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.518. Val Loss: 1.717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:57<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.532. Val Loss: 1.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:54<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.527. Val Loss: 1.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:54<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.519. Val Loss: 1.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.536. Val Loss: 1.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.482. Val Loss: 1.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.485. Val Loss: 1.668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.494. Val Loss: 1.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.472. Val Loss: 1.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.479. Val Loss: 1.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.485. Val Loss: 1.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.506. Val Loss: 1.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.494. Val Loss: 1.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.468. Val Loss: 1.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:53<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.462. Val Loss: 1.614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.470. Val Loss: 1.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1226/1226 [07:52<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1226 | Train Loss: 1.484. Val Loss: 1.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.443. Val Loss: 1.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1226/1226 [07:52<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1226 | Train Loss: 1.455. Val Loss: 1.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.473. Val Loss: 1.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.451. Val Loss: 1.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.488. Val Loss: 1.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1226/1226 [07:50<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1226 | Train Loss: 1.425. Val Loss: 1.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.424. Val Loss: 1.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.444. Val Loss: 1.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.472. Val Loss: 1.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.439. Val Loss: 1.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.407. Val Loss: 1.550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.439. Val Loss: 1.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.440. Val Loss: 1.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:50<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.436. Val Loss: 1.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.424. Val Loss: 1.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1226/1226 [07:50<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1226 | Train Loss: 1.436. Val Loss: 1.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1226/1226 [07:50<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1226 | Train Loss: 1.443. Val Loss: 1.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.425. Val Loss: 1.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.458. Val Loss: 1.520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.413. Val Loss: 1.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.471. Val Loss: 1.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.442. Val Loss: 1.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.440. Val Loss: 1.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.445. Val Loss: 1.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.477. Val Loss: 1.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.436. Val Loss: 1.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.448. Val Loss: 1.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.458. Val Loss: 1.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.500. Val Loss: 1.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.447. Val Loss: 1.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.443. Val Loss: 1.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.480. Val Loss: 1.490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.445. Val Loss: 1.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.464. Val Loss: 1.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.471. Val Loss: 1.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.476. Val Loss: 1.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.503. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.457. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.475. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.489. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.509. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.489. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.453. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.447. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.493. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.468. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.441. Val Loss: 1.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.451. Val Loss: 1.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:50<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.440. Val Loss: 1.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.494. Val Loss: 1.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.444. Val Loss: 1.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:52<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.429. Val Loss: 1.490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:51<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.425. Val Loss: 1.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [07:53<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1228 | Train Loss: 1.414. Val Loss: 1.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1226/1226 [07:50<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1226 | Train Loss: 1.455. Val Loss: 1.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1229/1229 [07:51<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1229 | Train Loss: 1.417. Val Loss: 1.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:50<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.404. Val Loss: 1.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:50<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.414. Val Loss: 1.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1227/1227 [07:50<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1227 | Train Loss: 1.447. Val Loss: 1.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 291/1227 [01:48<05:47,  2.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/UrkoAllende/OneDrive - AMC/learning-projects/PyTorch/TinyStories/TS full ds training_2.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/UrkoAllende/OneDrive%20-%20AMC/learning-projects/PyTorch/TinyStories/TS%20full%20ds%20training_2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m logits, loss \u001b[39m=\u001b[39m m(Xb, Yb)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/UrkoAllende/OneDrive%20-%20AMC/learning-projects/PyTorch/TinyStories/TS%20full%20ds%20training_2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/UrkoAllende/OneDrive%20-%20AMC/learning-projects/PyTorch/TinyStories/TS%20full%20ds%20training_2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/UrkoAllende/OneDrive%20-%20AMC/learning-projects/PyTorch/TinyStories/TS%20full%20ds%20training_2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/UrkoAllende/OneDrive%20-%20AMC/learning-projects/PyTorch/TinyStories/TS%20full%20ds%20training_2.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mLoss/train\u001b[39m\u001b[39m'\u001b[39m, loss, steps)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "steps = 1\n",
    "for file in files:\n",
    "    if file.startswith('tns'):\n",
    "        train = torch.load(data_path + file)\n",
    "        total_batches = calculate_total_batches(train, block_size, batch_size)\n",
    "        train_dl = make_batches(train, block_size, batch_size)\n",
    "\n",
    "        for epoch, (Xb, Yb) in enumerate(tqdm(train_dl, total=total_batches)):\n",
    "\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = get_lr(steps)\n",
    "\n",
    "            Xb, Yb = Xb.to(device), Yb.to(device)\n",
    "            logits, loss = m(Xb, Yb)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            writer.add_scalar('Loss/train', loss, steps)\n",
    "            steps += 1\n",
    "\n",
    "            if (epoch+1) % 100 == 0:\n",
    "                _, val_loss = estimate_loss(m, train, val, block_size, batch_size, eval_iters)\n",
    "                writer.add_scalar('Loss/val', val_loss, steps)\n",
    "\n",
    "        train_loss, val_loss = estimate_loss(m, train, val, block_size, batch_size, eval_iters)\n",
    "\n",
    "        if steps >= max_iters:\n",
    "            break\n",
    "\n",
    "# save torch model\n",
    "torch.save(m.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ ly ⁇  parked with ⁇  Sarah ⁇  A lady ⁇  her mom ⁇  and Sarah ⁇ s mom ⁇ .  ⁇ There is no park right here, ⁇  Sarah ⁇ s little girl  ⁇ Ok, ⁇  \"But why do you need to be the first to be the first to follow the orders?\" Sarah ⁇ s mom ⁇ s eyes lit up ⁇  \"Of course! I ⁇ ll help you get the right number  ⁇  to follow the way he is in such fun and safe\". Sarah smiled and said \"That\\'s the way I\\'ve to follow the laws of the park!\". <|endoftext|> One day, a little boat named Bobby went for a harbor. Bobby was a very independent boat. He loved to go on new water and play with the other boats. Bobby saw a big boat named  ⁇ room, and he wanted to be friends too. Bobby said to  ⁇ room, \"Look at my new toy! I\\'m big and I can play with your boat!\"  ⁇ room said, \"Okay, let\\'s play together!\" But Bobby did not want to play with  ⁇ room, so he was having too much fun.  ⁇ room asked Bobby, \"Can we play with my boat, please?\" Bobby thought for a moment and said, \"Okay, let\\'s play with my boat. But we must be careful where we play hide and seek.\" So Bobby and  ⁇ room played and built their boat in the pond. They played together every day and became very good friends. <|endoftext|> Once upon a time, there was a little green frog. The frog loved to jump and play in the pond. One day, the frog met a new friend, a little duck. The little duck was very happy to have a new friend. The little duck said, \"I want to play with you, frog!\" The frog said, \"Okay!\" They jumped and played together all day. They were having so much fun in the pond. As the sun began to set, the little duck and the green frog were very happy. They went back to their homes and told their families about their fun day. The other friends also liked to jump and play in the pond. The little duck made many friends and was never miserable again. <|endoftext|> Once upon a time, there was a kind boy named Tom. He liked to help his mom and dad. One day, Tom saw his mom using things at the store. His mom mentioned it to her to buy some things. Tom went to his mom and said, \"Mom, can I help? Can we please have that toy?\" His mom was happy and said, \"Yes, Tom, we can get some coins for you!\" Tom was excited to help his mom. As they were leaving the store, Tom\\'s mom told him to count his toy car. She said that it will be very useful and they need to do it quickly. Tom counted one, two, three, four, five coins. When Tom was done, he looked at his mom with the help of the help of her. His mom smiled and said, \"Tom, you are a great helper!\" Tom felt proud and was very happy to help his mom. The moral of the story is that being useful and helpful to others is important. <|endoftext|> Once upon a time, there was a little cat named Tom. One day, Tom was feeling very bored. He did not want to play. So, Tom found a toy to play with, but no string with his favorite thing ⁇  cord. The next day, Tom saw a cord on the floor. He had an idea. He thought maybe his toy mouse could play with the cord. Tom got the toy mouse and played with it. He pulled the cord around and around, making him laugh. All the friends saw this and wanted to play with the toy mouse too. They all played together, and soon everyone was happy again. <|endoftext|> One day, a little boy named Tim went to the park. He saw a huge tree and wanted to climb it. Tim was very excited, so he started to climb. As he climbed, he saw a little girl named Sue who was trying to reach the top. \"Hi, Tim!\" said Sue. \"Can I help you?\" Tim thought for a moment and said, \"Yes, let\\'s be friends!\" Tim was so happy that he and Sue would make friends and have fun at the park. As they were climbing the tree, something unexpected happened. A big wind came and blew Tim\\'s hat off his head! Sue had an idea. \"Let\\'s find sticks and leaves together!\" she said. They found many sticks and leaves. They made a big pile of the sticks and leaves. Finally, they made a new friend, the wind, and they had a great day at the park. <|endoftext|> One day, a big, bossy cat named Tom saw a little mouse named'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = \"Once upon a time\"\n",
    "tokenized_seed = t.encode(seed_text,False,False)  # Make sure to use your actual tokenization method\n",
    "tokenized_seed = torch.tensor(tokenized_seed).unsqueeze(0).to(device)  # Add a batch dimension\n",
    "\n",
    "# Generate 1000 new tokens\n",
    "generated_tokens = m.generate(tokenized_seed, max_new_tokens=1000)\n",
    "decoded_text = t.decode(generated_tokens[0].tolist())\n",
    "decoded_text[256:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
