{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "d_model = 128\n",
    "block_size = 8\n",
    "batch_size = 32\n",
    "n_heads = 4\n",
    "dropout = 0.1\n",
    "learning_rate = 1e-3\n",
    "epochs = 10_000\n",
    "eval_iters = 200\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, n_heads, d_model,  dropout=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.query = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.key = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.att_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(block_size, block_size), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        q = x\n",
    "        k = x\n",
    "        v = x\n",
    "        B,T,_ = x.shape \n",
    "        dk = d_model // n_heads\n",
    "\n",
    "        # linear projections\n",
    "        q = self.query(q) \n",
    "        k = self.key(k) \n",
    "        v = self.value(v) \n",
    "\n",
    "        # add number of heads\n",
    "        q = q.view(B,T,n_heads,dk).permute(0,2,1,3)   # B,T,h,dk\n",
    "        k = k.view(B,T,n_heads,dk).permute(0,2,1,3)  \n",
    "        v = v.view(B,T,n_heads,dk).permute(0,2,1,3)  \n",
    "        \n",
    "        # attention \n",
    "\n",
    "        x = q @ k.transpose(-2,-1) # B,h,T,dk @ B,h,dk,T --> B,h,T,T\n",
    "        x = x * dk ** -0.5 # B,h,T,T\n",
    "        x = x.masked_fill(self.mask, float('-inf')) # B,h,T,T\n",
    "        x = F.softmax(x, dim=(-1)) # B,n_h,T,T \n",
    "        x = x @ v  # B,h,T,T @ B,T,h,dv --> B,h,T,dv\n",
    "        B,h,T,dv = x.shape\n",
    "        x = x.transpose(2,1).contiguous().view(B,T,h*dv) #B,T,C\n",
    "        out = self.att_proj(x) # B,T,C\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.embedding_table = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Embedding(block_size, d_model)\n",
    "        self.mha = MultiHeadAttention(n_heads=n_heads, d_model=d_model)\n",
    "        self.lnorm = nn.LayerNorm(d_model)\n",
    "        self.out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "\n",
    "        embeds = self.embedding_table(x)\n",
    "        positions = self.pos_embedding(torch.arange(block_size, device=device))\n",
    "        x = embeds + positions\n",
    "\n",
    "        x = self.mha(x)\n",
    "        x = x + self.lnorm(x)\n",
    "        logits = self.out(x)\n",
    "\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(input=logits, target=targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3'].\n",
      "Vocab size: 65\n",
      "very dog to the commonalty.\n",
      "\n",
      "Second Citizen:\n",
      "Consi\n",
      "Training samples: 1003854\n",
      "Validation samples: 111539\n"
     ]
    }
   ],
   "source": [
    "data = open('text.txt').read()\n",
    "vocab = list(sorted(set(data)))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(f'Vocab: {vocab[:10]}.')\n",
    "print(f'Vocab size: {vocab_size}')\n",
    "\n",
    "stoi = {c:i for i, c in enumerate(vocab)}\n",
    "itos = {i:c for i, c in enumerate(vocab)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda i: ''.join([itos[i] for i in i])\n",
    "\n",
    "print(decode(encode(data[1100:1150])))\n",
    "data = torch.tensor(encode(data))\n",
    "\n",
    "n_tr = int(len(data) * 0.9)\n",
    "n_val = len(data) - n_tr\n",
    "\n",
    "train = data[:n_tr]\n",
    "val = data[n_tr+1:]\n",
    "\n",
    "print(f'Training samples: {train.shape[0]}')\n",
    "print(f'Validation samples: {val.shape[0]}')\n",
    "\n",
    "def make_batches(split):\n",
    "\n",
    "    data = train if split == 'train' else val\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "Xb, Yb = make_batches('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (embedding_table): Embedding(65, 128)\n",
      "  (pos_embedding): Embedding(8, 128)\n",
      "  (mha): MultiHeadAttention(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (query): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (key): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (value): Linear(in_features=128, out_features=128, bias=False)\n",
      "    (att_proj): Linear(in_features=128, out_features=128, bias=False)\n",
      "  )\n",
      "  (lnorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (out): Linear(in_features=128, out_features=65, bias=True)\n",
      ")\n",
      "Total parameters: 83521\n"
     ]
    }
   ],
   "source": [
    "m = Model(vocab_size).to(device)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "n_params = sum(p.nelement() for p in m.parameters())\n",
    "print(m)\n",
    "print(f'Total parameters: {n_params}')\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(m):\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = make_batches(split)\n",
    "            logits, loss = m(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 999. Training Loss: 2.232. Evaluation Loss: 2.291\n",
      "Iteration 1999. Training Loss: 2.166. Evaluation Loss: 2.241\n",
      "Iteration 2999. Training Loss: 2.145. Evaluation Loss: 2.227\n",
      "Iteration 3999. Training Loss: 2.129. Evaluation Loss: 2.214\n",
      "Iteration 4999. Training Loss: 2.106. Evaluation Loss: 2.195\n",
      "Iteration 5999. Training Loss: 2.076. Evaluation Loss: 2.191\n",
      "Iteration 6999. Training Loss: 2.077. Evaluation Loss: 2.191\n",
      "Iteration 7999. Training Loss: 2.075. Evaluation Loss: 2.188\n",
      "Iteration 8999. Training Loss: 2.076. Evaluation Loss: 2.179\n",
      "Iteration 9999. Training Loss: 2.053. Evaluation Loss: 2.147\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    Xb, Yb = make_batches('train')\n",
    "    logits, loss = m(Xb, Yb) # B, C\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 999:\n",
    "        l = estimate_loss(m)\n",
    "        print(f\"Iteration {epoch}. Training Loss: {l['train']:.3f}. Evaluation Loss: {l['val']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This llow oud by Valow, an, here naig? mate of coffers\n",
      "Bp of my to rne'llf to guonlifelf day how arve?\n",
      "Now son a strefeay whedes nowits: it; this your drist.\n",
      "The herime,\n",
      "And might for gancoun, thriastit\n",
      "you bofeth with therow heres he feerse not'cds lead's hing bestany for saminger rouu, sirsfoe llo slain lan sand will to caus ucher, from dan caby wang, and the good, th ean and to it your and queighth holity, wsir.\n",
      "\n",
      "ROMPEY:\n",
      "Je agphows, gain pe goitnt, whesir,\n",
      "A bawild do thyseane.\n",
      "\n",
      "EL:\n",
      "I love fo\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros(1, block_size).int().to(device)\n",
    "predictions = m.generate(context, 500)\n",
    "print(decode(predictions[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
